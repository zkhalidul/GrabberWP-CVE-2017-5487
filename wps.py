import requests
import re
from bs4 import BeautifulSoup
import time

start_time = time.time()

def get_start(page):
    req = requests.get('https://leakix.net/search?page={}&q=%2Bwordpress&scope=leak'.format(page))
    return BeautifulSoup(req.text, 'html.parser')

def get_url(pages: int):
    hasil = set()
    for page in range(0, pages):
        bs = get_start(page)
        for link in bs.find_all('div', {'class':'col-xl-8 text-end'}):
            for url in link.find_all('a', href=re.compile("\?[a-z\_]+\=\/wp\/v2\/users\/")):
                hasil.add(url.attrs['href'])
    return hasil

def get_listcred(pages: int):
    res = []
    for page in range(0, pages):
        bs = get_start(page)
        for txt in bs.select('pre > code'):
            res.append(txt.get_text()[39:])
    return res

if __name__ == '__main__':
    print("""
            GRAB SITE WORDPRESS(CVE-2017-5487)
            [*] select mode:
            [1] get list credentials
            [2] get list urls
    """)
    mode = int(input('[select mode]> '))
    depe = int(input('[jumlah halaman]> '))
    if mode == 1:
        print('mode [1]')
        print('TUNGGU..')
        res = get_listcred(depe)
        for has in res:
            print(has)
        print('Done in {:.2f} seconds'.format(time.time() - start_time))
    elif mode == 2:
        print('mode [2]')
        print('TUNGGU..')
        hasil = get_url(depe)
        for i, h in enumerate(hasil):
            print(f'[{i}]Found --> {h}')
        print('Done in {:.2f} seconds'.format(time.time() - start_time))
    else:
        print('No selected :(')
