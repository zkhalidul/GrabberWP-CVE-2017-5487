from urllib.request import urlopen
from urllib.request import HTTPError
from bs4 import BeautifulSoup
import re

def get_start(url):
    try:
        web = urlopen(url)
    except HTTPError as e:
        print(e)
    return BeautifulSoup(web.read(), 'html.parser')

def pars(content):
    bs = get_start(content)
    links = bs.find_all('div', {'class':'col-xl-8 text-end'})
    out = []
    for link in links:
        hasil = bs.find_all('a', href=re.compile("\?[a-z\_]+\=\/wp\/v2\/users\/"))
        if hasil is not None:
            for x in hasil:
                out.append(x.attrs['href'])
    return out

target = 'https://leakix.net/search?scope=leak&q=%3Frest_route%3D%2Fwp%2Fv2%2Fusers%2F'
out = pars(target)
hasil = set()
for x in out:
    hasil.add(x)
    for i in hasil:
        print(i)
